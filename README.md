# Question Answering Project

**Comparative Analysis of Transformer Models on SQuAD 2.0 for Machine Reading Comprehension**

## ðŸ“Œ Problem Overview

This project focuses on building and evaluating question answering models capable of understanding natural language questions and extracting accurate answers from provided passages. The models are also expected to detect when a question is unanswerable based on the context and refrain from guessing in such cases.

## ðŸ“‚ Dataset

**Stanford Question Answering Dataset (SQuAD 2.0)** â€“ [Explore Dataset](https://rajpurkar.github.io/SQuAD-explorer/)
SQuAD 2.0 is a widely used benchmark for machine reading comprehension. It contains:

* Over 100,000 crowd-sourced question-answer pairs.
* A mix of **answerable** and **unanswerable** questions to test model robustness and reasoning.
* Passages sourced from a diverse set of Wikipedia articles.

## ðŸ§  Model

We fine-tuned transformer-based models on SQuAD 2.0 and conducted a comparative analysis.
Access the fine-tuned model here: [Download Model](https://drive.google.com/file/d/1pZ7RMna1DNQs8VuCEPlZ0k7deITP9sMn/view?usp=drive_link)



